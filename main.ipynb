{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the directory path of the ear dataset\n",
    "DATASET_DIR = '/path/to/ear/dataset'\n",
    "\n",
    "# Define the number of classes (different individuals) in the dataset\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Define the size of the input image\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "# Define the batch size and number of epochs for training\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Load the dataset and preprocess the images\n",
    "data = []\n",
    "labels = []\n",
    "for i, folder_name in enumerate(os.listdir(DATASET_DIR)):\n",
    "    for filename in os.listdir(os.path.join(DATASET_DIR, folder_name)):\n",
    "        img_path = os.path.join(DATASET_DIR, folder_name, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        data.append(img)\n",
    "        labels.append(i)\n",
    "data = np.array(data, dtype='float32')\n",
    "data /= 255\n",
    "data = np.reshape(data, (data.shape[0], IMG_SIZE[0], IMG_SIZE[1], 1))\n",
    "labels = np_utils.to_categorical(labels, NUM_CLASSES)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
