{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting gpu growth\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "for g in gpu:\n",
    "    tf.config.experimental.set_memory_growth(g, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospath = os.path.join('data', 'positive')\n",
    "negpath = os.path.join('data', 'negative')\n",
    "anchor = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(pospath)\n",
    "# os.makedirs(negpath)\n",
    "# os.makedirs(anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap  = cv2.VideoCapture(0)\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     frame = frame[80:250+80, 200:250+200, :]    \n",
    "#     cv2.imshow('image', frame)   \n",
    "#     if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "#         img = os.path.join(anchor, '{}.jpg'.format(uuid.uuid1()))\n",
    "#         cv2.imwrite(img, frame)\n",
    "        \n",
    "#     if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "#         img = os.path.join(pospath, '{}.jpg'.format(uuid.uuid1()))\n",
    "#         cv2.imwrite(img, frame)\n",
    "#     if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "#         break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for directories in os.listdir(\"lfw\"):\n",
    "#     for files in os.listdir(os.path.join('lfw',directories)):\n",
    "#         ex = os.path.join(\"lfw\", directories, files)\n",
    "#         new = os.path.join(negpath, files)\n",
    "#         os.replace(ex, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataset(path):\n",
    "    return tf.data.Dataset.list_files(path+\"\\*.jpg\").take(150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = createdataset(pospath)\n",
    "neg = createdataset(negpath)\n",
    "anch = createdataset(anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n",
      "<TakeDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n",
      "<TakeDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(pos, neg, anch, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'data\\\\positive\\\\2b5b7cbc-d0af-11ed-9782-e45e37ecec6b.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pos.as_numpy_iterator()\n",
    "test.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(150,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones(len(anch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anch, pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(anch)))))\n",
    "negatives = tf.data.Dataset.zip((anch, neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anch)))))\n",
    "rawdata = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>\n",
      "<ZipDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>\n",
      "<ConcatenateDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(positives, negatives, rawdata, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'data\\\\anchor\\\\b12fe2ca-d0ae-11ed-96e5-e45e37ecec6b.jpg',\n",
       " b'data\\\\positive\\\\c0956b3f-d0ae-11ed-abaf-e45e37ecec6b.jpg',\n",
       " 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = rawdata.as_numpy_iterator()\n",
    "test.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    byteimg = tf.io.read_file(path)\n",
    "    img = tf.io.decode_jpeg(byteimg)\n",
    "    img = tf.image.resize(img, (100, 100))\n",
    "    img /= 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1,2,3],\n",
    " [4,5,6],\n",
    " [7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(inputimg, validationimg, label):\n",
    "    return (preprocess(inputimg), preprocess(validationimg), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rawdata.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.5245098 , 0.5507353 , 0.56421566],\n",
       "         [0.5156863 , 0.5534314 , 0.5620098 ],\n",
       "         [0.5083333 , 0.5534314 , 0.55539215],\n",
       "         ...,\n",
       "         [0.6580882 , 0.72083336, 0.77181375],\n",
       "         [0.64436275, 0.7129902 , 0.75514704],\n",
       "         [0.6382353 , 0.7088235 , 0.7480392 ]],\n",
       " \n",
       "        [[0.5183824 , 0.5644608 , 0.5713235 ],\n",
       "         [0.5176471 , 0.5637255 , 0.57058823],\n",
       "         [0.50686276, 0.5529412 , 0.5598039 ],\n",
       "         ...,\n",
       "         [0.6495098 , 0.7144608 , 0.7593137 ],\n",
       "         [0.6512255 , 0.7147059 , 0.764951  ],\n",
       "         [0.65588236, 0.71936274, 0.76960784]],\n",
       " \n",
       "        [[0.50784314, 0.57058823, 0.57058823],\n",
       "         [0.51960784, 0.57598037, 0.57916665],\n",
       "         [0.51004905, 0.55833334, 0.5644608 ],\n",
       "         ...,\n",
       "         [0.6490196 , 0.7176471 , 0.7676471 ],\n",
       "         [0.6598039 , 0.72843134, 0.77843136],\n",
       "         [0.6517157 , 0.7223039 , 0.7713235 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.3987745 , 0.41936275, 0.42818627],\n",
       "         [0.36838236, 0.389951  , 0.38897058],\n",
       "         [0.35759804, 0.36740196, 0.35759804],\n",
       "         ...,\n",
       "         [0.35171568, 0.36593136, 0.36838236],\n",
       "         [0.3509804 , 0.36078432, 0.35882354],\n",
       "         [0.35      , 0.35686275, 0.35588235]],\n",
       " \n",
       "        [[0.37867647, 0.40808824, 0.4139706 ],\n",
       "         [0.35171568, 0.3732843 , 0.37426472],\n",
       "         [0.33700982, 0.34681374, 0.34289217],\n",
       "         ...,\n",
       "         [0.34215686, 0.34313726, 0.3509804 ],\n",
       "         [0.3379902 , 0.34485295, 0.35171568],\n",
       "         [0.3242647 , 0.3252451 , 0.33308825]],\n",
       " \n",
       "        [[0.36053923, 0.39019608, 0.40710783],\n",
       "         [0.26642156, 0.28431374, 0.29705882],\n",
       "         [0.2529412 , 0.25392157, 0.2622549 ],\n",
       "         ...,\n",
       "         [0.3740196 , 0.34019607, 0.3497549 ],\n",
       "         [0.3622549 , 0.3509804 , 0.35490197],\n",
       "         [0.3372549 , 0.32941177, 0.34117648]]], dtype=float32),\n",
       " array([[[0.5323529 , 0.5715686 , 0.57941175],\n",
       "         [0.53039217, 0.56960785, 0.577451  ],\n",
       "         [0.5245098 , 0.55784315, 0.5656863 ],\n",
       "         ...,\n",
       "         [0.6218137 , 0.7120098 , 0.7355392 ],\n",
       "         [0.6276961 , 0.70906866, 0.7355392 ],\n",
       "         [0.6313726 , 0.70980394, 0.74509805]],\n",
       " \n",
       "        [[0.53406864, 0.5732843 , 0.5772059 ],\n",
       "         [0.5252451 , 0.5644608 , 0.5683824 ],\n",
       "         [0.5176471 , 0.5568628 , 0.56078434],\n",
       "         ...,\n",
       "         [0.63308823, 0.720098  , 0.75514704],\n",
       "         [0.6360294 , 0.714951  , 0.7522059 ],\n",
       "         [0.64117646, 0.71960783, 0.75686276]],\n",
       " \n",
       "        [[0.5232843 , 0.5625    , 0.56642157],\n",
       "         [0.53382355, 0.57303923, 0.5769608 ],\n",
       "         [0.5183824 , 0.55759805, 0.5615196 ],\n",
       "         ...,\n",
       "         [0.62941176, 0.71568626, 0.7588235 ],\n",
       "         [0.6377451 , 0.722549  , 0.7656863 ],\n",
       "         [0.64509803, 0.7294118 , 0.77254903]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.4151961 , 0.43088236, 0.43676472],\n",
       "         [0.36936274, 0.38284314, 0.38946077],\n",
       "         [0.36617646, 0.37083334, 0.38039216],\n",
       "         ...,\n",
       "         [0.44534314, 0.2752451 , 0.31446078],\n",
       "         [0.4127451 , 0.33431372, 0.3482843 ],\n",
       "         [0.35514706, 0.35343137, 0.35220587]],\n",
       " \n",
       "        [[0.3875    , 0.40612745, 0.41789216],\n",
       "         [0.35661766, 0.3745098 , 0.38627452],\n",
       "         [0.34387255, 0.35735294, 0.36985293],\n",
       "         ...,\n",
       "         [0.40710783, 0.19142157, 0.24754901],\n",
       "         [0.44852942, 0.27990195, 0.31691176],\n",
       "         [0.39803922, 0.30882353, 0.3245098 ]],\n",
       " \n",
       "        [[0.38259804, 0.40220588, 0.4139706 ],\n",
       "         [0.34289217, 0.3615196 , 0.3732843 ],\n",
       "         [0.32965687, 0.34534314, 0.35710785],\n",
       "         ...,\n",
       "         [0.28946078, 0.09803922, 0.1615196 ],\n",
       "         [0.4762255 , 0.24362744, 0.30465686],\n",
       "         [0.45490196, 0.27450982, 0.31764707]]], dtype=float32),\n",
       " 1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.as_numpy_iterator()\n",
    "test.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(): \n",
    "    inp = Input(shape=(100,100,3), name='input_image')\n",
    "    \n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "    \n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    # Third block \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding = make_embedding()\n",
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "    def call(self, input_emb, validation_emb):\n",
    "        return tf.math.abs(input_emb - validation_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32, name='input_img'), name='input_img', description=\"created by layer 'input_img'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32, name='val_img'), name='val_img', description=\"created by layer 'val_img'\")\n"
     ]
    }
   ],
   "source": [
    "inputimg = Input(name='input_img', shape=(100, 100, 3))\n",
    "validationimg = Input(name='val_img', shape=(100, 100, 3))\n",
    "print(inputimg, validationimg, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "siameselayer = L1Dist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='embedding/dense/Sigmoid:0', description=\"created by layer 'embedding'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='embedding/dense/Sigmoid:0', description=\"created by layer 'embedding'\")\n"
     ]
    }
   ],
   "source": [
    "inputembedding = embedding(inputimg)\n",
    "validationembedding = embedding(validationimg)\n",
    "print(inputembedding, validationembedding, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4096) dtype=float32 (created by layer 'l1_dist')>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = siameselayer(inputembedding, validationembedding)\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_1')>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Dense(1, activation='sigmoid')(distances)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x239222e9b10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testnetwork = Model(inputs=[inputimg, validationimg], outputs=classifier, name='SiameseNetwork')\n",
    "testnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    inputimg = Input(name='inputimg', shape=(100, 100, 3))\n",
    "    validationimg = Input(name='validationimg', shape=(100, 100, 3))\n",
    "    siameselayer = L1Dist()\n",
    "    siameselayer._name = 'distance'\n",
    "    distances = siameselayer(embedding(inputimg), embedding(validationimg))\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    return Model(inputs=[inputimg, validationimg], outputs=classifier, name='SiameseNetwork')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputimg (InputLayer)          [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validationimg (InputLayer)     [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['inputimg[0][0]',               \n",
      "                                                                  'validationimg[0][0]']          \n",
      "                                                                                                  \n",
      " distance (L1Dist)              (None, 4096)         0           ['embedding[2][0]',              \n",
      "                                                                  'embedding[3][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcl = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointdir = './checkpoints'\n",
    "checkpointprefix = os.path.join(checkpointdir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        X = batch[:2]\n",
    "        Y = batch[2]\n",
    "        y_pred = siamese_model(X, training=True)\n",
    "        loss = bcl(Y, y_pred)\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print(\"\\n EPOCH : {}/{}\".format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        for idx, batch in enumerate(data):\n",
    "            train_step(batch)\n",
    "            progbar.update(idx+1)\n",
    "        if epoch%50==0:\n",
    "            checkpoint.save(file_prefix=checkpointprefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH : 1/50\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
